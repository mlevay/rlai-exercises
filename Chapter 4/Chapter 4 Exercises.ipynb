{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.1\n",
    "\n",
    "## Question:\n",
    "In Example 4.1, if $\\pi$ is the equiprobable random policy, what is $q_{\\pi}(11,down)$?\n",
    "What is $q_{\\pi}(7,down)$?\n",
    "## Answer:\n",
    "\\begin{equation*}\n",
    "q_{\\pi}(s,a) = \\sum_{s',r} p(s',r|s,a) [r + \\gamma v_{\\pi}(s')]\n",
    "\\end{equation*}\n",
    "Therefore,\n",
    "\\begin{equation*}\n",
    "q_{\\pi}(11,down) = 1 \\cdot (-1 + 1 \\cdot 0) = 0 \\\\\n",
    "q_{\\pi}(7,down) = 1 \\cdot (-1 + 1 \\cdot (-14)) = -14\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.2\n",
    "\n",
    "## Question:\n",
    "In Example 4.1, suppose a new state $15$ was added to the gridworld just below state $13$, and its actions, $left$, $up$, $right$ and $down$, take the agent to states $12$, $13$, $14$ and $15$, respectively. Assume that the transitions ___from___ the original states are unchanged. What, then, is $v_{\\pi}(15)$ for the equiprobable random policy? Now suppose the dynamics of state $13$ are also changed, such that action $down$ from state $13$ takes the agent to the new state $15$. What is $v_{\\pi}(15)$ for the equiprobable random policy in this case?\n",
    "\n",
    "## Answer:\n",
    "With still unchanged transitions ___from___ the original states, there is no way to get to state $15$ unless already in it (because $p(13|13,down) = 1$ and $p(15|13,down) = 0$). Therefore, no other state's value is dependent upon state $15$ than state $15$ itself.\n",
    "\n",
    "The general equation for state value is, in this example:\n",
    "\\begin{equation*}\n",
    "v_{\\pi}(s) = \\sum_{a} \\pi(a|s) \\sum_{s',r} p(s',r|s,a) [r + \\gamma v_{\\pi}(s')]\n",
    "\\\\ = \\frac{1}{4} \\sum_{a}[v_{\\pi}(s') - 1]\n",
    "\\end{equation*}\n",
    "\n",
    "Seven state value update iterations using the below equation are sufficient for $v(15)$ to clearly approximate -20:\n",
    "\\begin{equation*}\n",
    "v_{\\pi}(15) = \\frac{1}{4} \\big( v_{\\pi}(12) - 1 + [v_{\\pi}(13) - 1 + [v_{\\pi}(14) - 1 + [v_{\\pi}(15) - 1 \\big) \\\\\n",
    "v_{1}(15) = -15 \\\\\n",
    "v_{2}(15) = -18.75 \\\\\n",
    "v_{3}(15) = -19.6875 \\\\\n",
    "v_{4}(15) = -19.921875 \\\\\n",
    "v_{5}(15) = -19.98046875 \\\\\n",
    "v_{6}(15) = -19.9961171875 \\\\\n",
    "v_{7}(15) = -19.998779296875 \\approx -20 \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "With the change in dynamics of state $13$, there is now a path to state $15$ - from state $13$. The value of state $13$ (and, subsequently, of all of its possible predecessor states) would need to be updated to reflect the new dynamics. To update the value state from $v_{\\pi, old}(13)$ to $v_{\\pi, new}(13)$, one would only need to substitute $v_{\\pi}(13)$ by $v_{\\pi}(15)$ to reflect the action $down$ - the rest of the calculation remains the same. However, the problem states $v_{*}(13)= -20$ and we already arrived at $v_{*}(15) = -20$. Hence, the value of state $13$ will remain effectively unchanged, and so will its possible predecessor states' values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.3\n",
    "\n",
    "## Question:\n",
    "What are the equations analogous to (4.3), (4.4), and (4.5) for the actoin-value function $q_{\\pi}$ and its successive approximation by a sequence of functions $q_0$, $q_1$, $q_2$, ...? \n",
    "\n",
    "## Answer:\n",
    "\\begin{equation*}\n",
    "q_{\\pi}(s,a) = \\mathbb{E}[G_t | S_t=s, A_t = a] \n",
    "\\\\ =  \\mathbb{E}[R_{t+1} + \\gamma G_{t+1} | S_t=s, A_t = a] \n",
    "\\\\ =  \\mathbb{E}[R_{t+1} + \\gamma q_{\\pi}(S_{t+1}, A_{t+1}) | S_t=s, A_t = a] \n",
    "\\\\ = \\sum_{s',r} p(s',r|s,a) \\big[ r + \\gamma \\sum_{a'} \\pi(a'|s') q_{\\pi}(s',a') \\big] \\\\\n",
    "q_{k+1}(s,a) = \\mathbb{E}[R_{t+1} + \\gamma q_{k}(S_{t+1}, A_{t+1}) | S_t=s, A_t = a] \n",
    "\\\\ = \\sum_{s',r} p(s',r|s,a) \\big[ r + \\gamma \\sum_{a'} \\pi(a'|s') q_{k}(s',a') \\big] \\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.4\n",
    "\n",
    "## Question:\n",
    "The policy iteration algorithm on page 80 has a subtle bug in that it may never terminate if the policy continually switches between two or more policies that are equally good. This is ok for pedagogy, but not for actual use. Modify the pseudocode so convergence is guaranteed.\n",
    "\n",
    "## Answer:\n",
    "The corrected algorithm is:\n",
    "1. Initialization\n",
    "\n",
    "   <div>$V(s) \\in \\mathbb{R}$ and $\\pi(s) \\in A(s)$ arbitrarily for all $s \\in S$</div>\n",
    "   <div>&nbsp;</div>\n",
    "   \n",
    "2. Policy Evaluation\n",
    "\n",
    "   <div>Loop:</div> \n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$\\Delta \\leftarrow 0$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>Loop for each $s \\in S:$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$v \\leftarrow V(s)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$V(s) \\leftarrow \\sum_{s',r} p(s',r|s,\\pi(s))[r + \\gamma V(s')]$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$\\Delta \\leftarrow max(\\Delta, |v - V(s)|)$</div>\n",
    "   <div>until $\\Delta < \\Theta$ (a small positive number determining the accuracy of estimation)</div> \n",
    "   <div>&nbsp;</div>\n",
    "   \n",
    "3. Policy Improvement\n",
    "\n",
    "   <div>$policy$-$stable \\leftarrow true$</div>\n",
    "   <div>For each $s \\in S$:</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$old$-$action \\leftarrow \\pi(s)$</div>\n",
    "   <div style=\"background-color:#ffffaa\"><i>&nbsp;&nbsp;&nbsp;</i>$old$-$value \\leftarrow V(s)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$\\pi(s) \\leftarrow argmax_{a} \\sum_{s',r} p(s',r|s,a)[r + \\gamma V(s')]$</div>\n",
    "   <div style=\"background-color:#ffffaa\"><i>&nbsp;&nbsp;&nbsp;</i>$new$-$value \\leftarrow \\sum_{s',r} p(s',r|s,\\pi(s))[r + \\gamma V(s')]$</div>\n",
    "   <div style=\"background-color:#ffffaa\"><i>&nbsp;&nbsp;&nbsp;</i>If $old$-$action \\neq \\pi(s)$ and $old$-$value < new$-$value$, then $policy$-$stable \\leftarrow false$</div>\n",
    "   <div>If $policy$-$stable$, then stop and return $V \\approx v_*$ and $\\pi \\approx \\pi_*$; else go to 2</div>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.5\n",
    "\n",
    "## Question:\n",
    "How would policy iteration be defined for action values? Give a complete algorithm for computing $q_*$, analogous to that on page 80 for computing $v_*$. Please pay special attention to this exercise, because the ideas involved will be used throughout the rest of this book.\n",
    "\n",
    "## Answer:\n",
    "The algorithm for finding optimal action-values is:\n",
    "1. Initialization\n",
    "\n",
    "   <div>$Q(s,a) \\in \\mathbb{R}$ and $\\pi(s) \\in A(s)$ arbitrarily for all $s \\in S$, $a \\in A(s)$</div>\n",
    "   <div>&nbsp;</div>\n",
    "   \n",
    "2. Policy Evaluation\n",
    "\n",
    "   <div>Loop:</div> \n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$\\Delta \\leftarrow 0$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>Loop for each $s \\in S$, $a \\in A(s)$:</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$q \\leftarrow Q(s,a)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$Q(s,a) \\leftarrow \\sum_{s',r} p(s',r|s,a)[r + \\gamma Q(s',\\pi(s))]$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$\\Delta \\leftarrow max(\\Delta, |q - Q(s,a)|)$</div>\n",
    "   <div>until $\\Delta < \\Theta$ (a small positive number determining the accuracy of estimation)</div> \n",
    "   <div>&nbsp;</div>\n",
    "   \n",
    "3. Policy Improvement\n",
    "\n",
    "   <div>$policy$-$stable \\leftarrow true$</div>\n",
    "   <div>For each $s \\in S$:</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$old$-$action \\leftarrow \\pi(s)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$old$-$value \\leftarrow V(s)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$\\pi(s) \\leftarrow argmax_{a} Q(s,a)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$new$-$value \\leftarrow \\sum_{s',r} p(s',r|s,a)[r + \\gamma Q(s',\\pi(s))]$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>If $old$-$action \\neq \\pi(s)$ and $old$-$value < new$-$value$, then $policy$-$stable \\leftarrow false$</div>\n",
    "   <div>If $policy$-$stable$, then stop and return $Q \\approx q_*$ and $\\pi \\approx \\pi_*$; else go to 2</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.6\n",
    "\n",
    "## Question:\n",
    "\n",
    "Suppose you are restricted to considering only policies that are $\\epsilon$___-soft___, meaning that the probability of selecting each item in each state, $s$, is at least $\\frac{\\epsilon}{|A(s)|}$. Describe qualitatively the changes that would be required in each of the steps $3$, $2$, and $1$, in that order, of the policy iteration algorithm for $v_*$ on page 80.\n",
    "## Answer:\n",
    "The necessary changes to the algorithm are:\n",
    "1. Initialization\n",
    "\n",
    "   <div style=\"background-color:#ffffaa\">$V(s) \\in \\mathbb{R}$ arbitrarily for all $s \\in S$</div>\n",
    "   <div style=\"background-color:#ffffaa\">$\\pi(s) \\leftarrow $ random action from $A(s)$ with $p = \\frac{1}{|A(s)|}$</div>\n",
    "   <div>&nbsp;</div>\n",
    "   \n",
    "2. Policy Evaluation\n",
    "\n",
    "   <div>Loop:</div> \n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$\\Delta \\leftarrow 0$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>Loop for each $s \\in S:$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$v \\leftarrow V(s)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$V(s) \\leftarrow \\sum_{s',r} p(s',r|s,\\pi(s))[r + \\gamma V(s')]$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$\\Delta \\leftarrow max(\\Delta, |v - V(s)|)$</div>\n",
    "   <div>until $\\Delta < \\Theta$ (a small positive number determining the accuracy of estimation)</div> \n",
    "   <div>&nbsp;</div>\n",
    "   \n",
    "3. Policy Improvement\n",
    "\n",
    "   <div>$policy$-$stable \\leftarrow true$</div>\n",
    "   <div>For each $s \\in S$:</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$old$-$action \\leftarrow \\pi(s)$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$old$-$value \\leftarrow V(s)$</div>\n",
    "   <div style=\"background-color:#ffffaa\"><i>&nbsp;&nbsp;&nbsp;</i>$\\pi(s)$</div>\n",
    "   <div style=\"background-color:#ffffaa\"><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$\\leftarrow a_* = argmax_{a} \\sum_{s',r} p(s',r|s,a) [r + \\gamma V(s')]$, with $p = 1 - \\epsilon + \\frac{\\epsilon}{|A(s)|}$, or</div>\n",
    "   <div style=\"background-color:#ffffaa\"><i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>$\\leftarrow$ any $a \\neq a_*$, with $p = \\frac{\\epsilon}{|A(s)|}$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>$new$-$value \\leftarrow \\sum_{s',r} p(s',r|s,\\pi(s))[r + \\gamma V(s')]$</div>\n",
    "   <div><i>&nbsp;&nbsp;&nbsp;</i>If $old$-$action \\neq \\pi(s)$ and $old$-$value < new$-$value$, then $policy$-$stable \\leftarrow false$</div>\n",
    "   <div>If $policy$-$stable$, then stop and return $V \\approx v_*$ and $\\pi \\approx \\pi_*$; else go to 2</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.7 (programming)\n",
    "\n",
    "## Question:\n",
    "Write a program for policy iteration and re-solve Jack's car rental problem with the following changes. One of Jack's employees at the first location rides a bus home each night and lives near the second location. She is happy to shuttle one car to the second location for free. Each additional car still costs \\\\$2, as do all cars moved in the other direction. In addition, Jack has limited parking space at each location. If more than 10 cars are kept overnight at a location (after any moving of cars), than an additional cost of \\\\$4 must be incurred to use a second parking lot (independent of how many cars are kept there). These sorts of non-linearities and arbitrary dynamics often occur in real problems and cannot easily be handled by optimization methods other than dynamic programming. To check your program, first replicate the results given for the original problem. \n",
    "\n",
    "## Answer:\n",
    "Common declarations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "\n",
    "PATH_SPRENRET_CSV = \"C:/Temp/rlai-exercises/Chapter 4/data\"\n",
    "\n",
    "MIN_NUMBER_OF_CARS_LOC_1 = 0\n",
    "MIN_NUMBER_OF_CARS_LOC_2 = 0\n",
    "MAX_NUMBER_OF_CARS_LOC_1 = 20\n",
    "MAX_NUMBER_OF_CARS_LOC_2 = 20\n",
    "MAX_NUMBER_OF_CARS_PER_TRANSFER = 5\n",
    "INDEX_FIRST_CHARGEABLE_TRANSFER = 0\n",
    "INDEX_LAST_CHARGEABLE_TRANSFER = 4\n",
    "UNIT_COST_OF_TRANSFER = 2\n",
    "EXP_VALUE_RENTALS_LOC_1 = 3\n",
    "EXP_VALUE_RENTALS_LOC_2 = 4\n",
    "EXP_VALUE_RETURNS_LOC_1 = 3\n",
    "EXP_VALUE_RETURNS_LOC_2 = 2\n",
    "REWARD_PER_RENTAL = 10\n",
    "\n",
    "# Constants for the dataframe dfS_A_Sp\n",
    "DFCOL_SASP_SORIG = \"s_k\"\n",
    "DFCOL_SASP_ACTION = \"a_k\" # for each original state, a number of actions are valid and possible\n",
    "DFCOL_SASP_IS_VALID = \"is_valid\"\n",
    "DFCOL_SASP_SPSEUDO = \"s_pseudo_k\" # each sequence (s,a) can result in a number of next states s'\n",
    "DFCOL_SASP_FEES = \"fees_k\"\n",
    "DFCOL_SASP_SORIG_A = \"s_k_a\"\n",
    "DFCOL_SASP_SORIG_B = \"s_k_b\"\n",
    "DFCOL_SASP_NUM_TRANSFERS = \"count_transfers\"\n",
    "DFCOL_SASP_SPSEUDO_A = \"s_pseudo_k_a\"\n",
    "DFCOL_SASP_SPSEUDO_B = \"s_pseudo_k_b\"\n",
    "\n",
    "# Constants for the dataframe dfSp_ren_ret\n",
    "DFCOL_SPRENRET_SPSEUDO = \"s_pseudo_k\"\n",
    "DFCOL_SPRENRET_RENTALS_A = \"rentals_k_a\"\n",
    "DFCOL_SPRENRET_RENTALS_B = \"rentals_k_b\"\n",
    "DFCOL_SPRENRET_RETURNS_A = \"returns_k_a\"\n",
    "DFCOL_SPRENRET_RETURNS_B = \"returns_k_b\"\n",
    "DFCOL_SPRENRET_IS_VALID = \"is_valid\"\n",
    "DFCOL_SPRENRET_SNEXT = \"s_k_plus_1\"\n",
    "DFCOL_SPRENRET_PROBSRSA = \"p_of_srsa\" # p(s',r|s,a)\n",
    "DFCOL_SPRENRET_REWARD = \"r_k_reward\" # each sequence (s,a,s') results in a unique reward r\n",
    "DFCOL_SPRENRET_SNEXT_A = \"s_k_plus_1_a\"\n",
    "DFCOL_SPRENRET_SNEXT_B = \"s_k_plus_1_b\"\n",
    "\n",
    "# Constants for the dataframe dfV\n",
    "DFCOL_V_STATE = \"s\" # s\n",
    "DFCOL_V_STATE_A = \"s_a\"\n",
    "DFCOL_V_STATE_B = \"s_b\"\n",
    "DFCOL_V_VALUE = \"v_of_s\" # v(s)\n",
    "\n",
    "# Constants for the dataframe dfPi\n",
    "DFCOL_PI_STATE = \"s\" # s\n",
    "DFCOL_PI_STATE_A = \"s_a\"\n",
    "DFCOL_PI_STATE_B = \"s_b\"\n",
    "DFCOL_PI_ACTION = \"a\" # a\n",
    "\n",
    "def get_state_name(state_a, state_b):\n",
    "    return state_a.zfill(2) + \"_\" + state_b.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        s_k  a_k s_pseudo_k  fees_k\n",
      "5     00_00    5      00_00       0\n",
      "16    00_01    5      00_01       0\n",
      "237   01_00    6      00_01       2\n",
      "469   02_00    7      00_02       4\n",
      "27    00_02    5      00_02       0\n",
      "248   01_01    6      00_02       2\n",
      "480   02_01    7      00_03       4\n",
      "38    00_03    5      00_03       0\n",
      "259   01_02    6      00_03       2\n",
      "701   03_00    8      00_03       6\n",
      "933   04_00    9      00_04       8\n",
      "712   03_01    8      00_04       6\n",
      "270   01_03    6      00_04       2\n",
      "49    00_04    5      00_04       0\n",
      "491   02_02    7      00_04       4\n",
      "1165  05_00   10      00_05      10\n",
      "281   01_04    6      00_05       2\n",
      "944   04_01    9      00_05       8\n",
      "60    00_05    5      00_05       0\n",
      "502   02_03    7      00_05       4\n",
      "723   03_02    8      00_05       6\n",
      "955   04_02    9      00_06       8\n",
      "513   02_04    7      00_06       4\n",
      "71    00_06    5      00_06       0\n",
      "1176  05_01   10      00_06      10\n",
      "734   03_03    8      00_06       6\n",
      "292   01_05    6      00_06       2\n",
      "1187  05_02   10      00_07      10\n",
      "745   03_04    8      00_07       6\n",
      "303   01_06    6      00_07       2\n",
      "...     ...  ...        ...     ...\n",
      "4105  17_16    2      20_13       6\n",
      "3663  15_18    0      20_13      10\n",
      "4768  20_13    5      20_13       0\n",
      "3674  15_19    0      20_14      10\n",
      "3895  16_18    1      20_14       8\n",
      "4116  17_17    2      20_14       6\n",
      "4779  20_14    5      20_14       0\n",
      "4558  19_15    4      20_14       2\n",
      "4337  18_16    3      20_14       4\n",
      "3906  16_19    1      20_15       8\n",
      "4569  19_16    4      20_15       2\n",
      "3685  15_20    0      20_15      10\n",
      "4127  17_18    2      20_15       6\n",
      "4790  20_15    5      20_15       0\n",
      "4348  18_17    3      20_15       4\n",
      "4359  18_18    3      20_16       4\n",
      "4801  20_16    5      20_16       0\n",
      "3917  16_20    1      20_16       8\n",
      "4138  17_19    2      20_16       6\n",
      "4580  19_17    4      20_16       2\n",
      "4370  18_19    3      20_17       4\n",
      "4149  17_20    2      20_17       6\n",
      "4812  20_17    5      20_17       0\n",
      "4591  19_18    4      20_17       2\n",
      "4602  19_19    4      20_18       2\n",
      "4823  20_18    5      20_18       0\n",
      "4381  18_20    3      20_18       4\n",
      "4613  19_20    4      20_19       2\n",
      "4834  20_19    5      20_19       0\n",
      "4845  20_20    5      20_20       0\n",
      "\n",
      "[3701 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the row count for the dfS_A_Sp dataframe\n",
    "num_states = (MAX_NUMBER_OF_CARS_LOC_1 - MIN_NUMBER_OF_CARS_LOC_1 + 1) * (MAX_NUMBER_OF_CARS_LOC_2 - MIN_NUMBER_OF_CARS_LOC_2 + 1)\n",
    "num_actions = MAX_NUMBER_OF_CARS_PER_TRANSFER*2 + 1 # all whole numbers in [-n, n]\n",
    "num_sasp = num_states * num_actions\n",
    "\n",
    "# Calculate all states\n",
    "all_sub_states_a = list(range(MIN_NUMBER_OF_CARS_LOC_1, MAX_NUMBER_OF_CARS_LOC_1 + 1))\n",
    "all_sub_states_b = list(range(MIN_NUMBER_OF_CARS_LOC_2, MAX_NUMBER_OF_CARS_LOC_2 + 1))\n",
    "all_states = np.array(np.meshgrid(all_sub_states_a, all_sub_states_b)).T.reshape(-1,2)\n",
    "#print(all_states)\n",
    "\n",
    "state_names = np.array([\"xx_xx\"] * num_states)\n",
    "for i in range(num_states):\n",
    "    state_name = get_state_name(str(all_states[i,0].item()), str(all_states[i,1].item()))\n",
    "    state_names[i] = state_name\n",
    "\n",
    "all_states = np.hstack((all_states, np.atleast_2d(state_names).T))\n",
    "dict_states_a = dict(zip(all_states[:,-1], all_states[:,0]))\n",
    "dict_states_b = dict(zip(all_states[:,-1], all_states[:,1]))\n",
    "#print(all_states)\n",
    "\n",
    "# Calculate all actions\n",
    "all_actions = np.array([list(range(-MAX_NUMBER_OF_CARS_PER_TRANSFER, MAX_NUMBER_OF_CARS_PER_TRANSFER+1))])\n",
    "#print(all_actions)\n",
    "\n",
    "action_names = np.array([0] * num_actions)\n",
    "for i in range(num_actions):\n",
    "    action_name = i\n",
    "    action_names[i] = action_name\n",
    "    \n",
    "all_actions = np.hstack((all_actions.T, np.atleast_2d(action_names).T))\n",
    "dict_actions = dict(zip(all_actions[:,-1], all_actions[:,0]))\n",
    "\n",
    "mindex = pd.MultiIndex.from_product(\n",
    "                [all_states[:,-1], all_actions[:,-1]],\n",
    "                names=[DFCOL_SASP_SORIG, DFCOL_SASP_ACTION]\n",
    "            )\n",
    "dfSASP = pd.DataFrame(\n",
    "            {\n",
    "                DFCOL_SASP_IS_VALID: [True]*num_sasp\n",
    "            },\n",
    "            index = mindex)\n",
    "\n",
    "dfSASP.reset_index(inplace=True)\n",
    "\n",
    "# compute # cars at location A for the pseudo state: DFCOL_SARS_SPSEUDO_A\n",
    "dfSASP[DFCOL_SASP_SPSEUDO_A] = dfSASP[DFCOL_SASP_SORIG].map(dict_states_a).astype(int) - dfSASP[DFCOL_SASP_ACTION].map(dict_actions).astype(int)\n",
    "\n",
    "# compute # cars at location B for the pseudo state': DFCOL_SARS_SPSEUDO_B\n",
    "dfSASP[DFCOL_SASP_SPSEUDO_B] = dfSASP[DFCOL_SASP_SORIG].map(dict_states_b).astype(int) + dfSASP[DFCOL_SASP_ACTION].map(dict_actions).astype(int)\n",
    "\n",
    "# Re-cast the columns as specific types to allow string operations\n",
    "dfSASP = dfSASP.astype({DFCOL_SASP_SPSEUDO_A: str, \n",
    "                        DFCOL_SASP_SPSEUDO_B: str})\n",
    "\n",
    "# compute the pseudo state (as of 6am - following transfers but prior to new rentals/returns)\n",
    "dfSASP[DFCOL_SASP_SPSEUDO] = dfSASP.apply(\n",
    "    lambda d: get_state_name(str(d[DFCOL_SASP_SPSEUDO_A]), str(d[DFCOL_SASP_SPSEUDO_B])),\n",
    "    axis=1)\n",
    "\n",
    "# Re-cast the columns as specific types to allow arithmetic operations\n",
    "dfSASP = dfSASP.astype({DFCOL_SASP_SPSEUDO_A: int, \n",
    "                        DFCOL_SASP_SPSEUDO_B: int})\n",
    "\n",
    "dfSASP.loc[dfSASP[DFCOL_SASP_SPSEUDO_A] < MIN_NUMBER_OF_CARS_LOC_1, [DFCOL_SASP_IS_VALID]] = False\n",
    "dfSASP.loc[dfSASP[DFCOL_SASP_SPSEUDO_B] < MIN_NUMBER_OF_CARS_LOC_2, [DFCOL_SASP_IS_VALID]] = False\n",
    "dfSASP.loc[dfSASP[DFCOL_SASP_SPSEUDO_A] > MAX_NUMBER_OF_CARS_LOC_1, [DFCOL_SASP_IS_VALID]] = False\n",
    "dfSASP.loc[dfSASP[DFCOL_SASP_SPSEUDO_B] > MAX_NUMBER_OF_CARS_LOC_2, [DFCOL_SASP_IS_VALID]] = False\n",
    "\n",
    "dfSASP = dfSASP.loc[dfSASP[DFCOL_SASP_IS_VALID] == True]\n",
    "dfSASP = dfSASP.iloc[:,[0,1,5]]\n",
    "\n",
    "dfSASP = dfSASP.sort_values(DFCOL_SASP_SPSEUDO)\n",
    "\n",
    "# compute fees for a\n",
    "dfSASP[DFCOL_SASP_FEES] = abs(dfSASP[DFCOL_SASP_ACTION].map(dict_actions).astype(int)*UNIT_COST_OF_TRANSFER)\n",
    "\n",
    "print(dfSASP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing done 22:03:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe creation done 22:17:37\n"
     ]
    }
   ],
   "source": [
    "# Calculate the row count for the dfSp_Ren_Ret dataframe\n",
    "num_states = (MAX_NUMBER_OF_CARS_LOC_1 - MIN_NUMBER_OF_CARS_LOC_1 + 1) * (MAX_NUMBER_OF_CARS_LOC_2 - MIN_NUMBER_OF_CARS_LOC_2 + 1)\n",
    "num_ren_values = (MAX_NUMBER_OF_CARS_LOC_1 - MIN_NUMBER_OF_CARS_LOC_1 + 1) * (MAX_NUMBER_OF_CARS_LOC_2 - MIN_NUMBER_OF_CARS_LOC_2 + 1)\n",
    "num_ret_values = (MAX_NUMBER_OF_CARS_LOC_1 - MIN_NUMBER_OF_CARS_LOC_1 + 1) * (MAX_NUMBER_OF_CARS_LOC_2 - MIN_NUMBER_OF_CARS_LOC_2 + 1)\n",
    "num_psrr = num_states * num_ren_values * num_ret_values\n",
    "\n",
    "# Calculate all rental and return values\n",
    "all_renret_values_a = np.array(list(range(MIN_NUMBER_OF_CARS_LOC_1, MAX_NUMBER_OF_CARS_LOC_1 + 1)))\n",
    "all_renret_values_b = np.array(list(range(MIN_NUMBER_OF_CARS_LOC_2, MAX_NUMBER_OF_CARS_LOC_2 + 1)))\n",
    "#print(all_renret_values_b)\n",
    "print(\"pre-processing done\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# helper function to calculate the probability of rentals & returns at a location\n",
    "def get_probsrsa_vectorized(number, exp_rate):\n",
    "    return np.power(exp_rate, number)*np.exp(-exp_rate)/scipy.special.factorial(number)\n",
    "\n",
    "# prepare a dtype=float lookup table for rental/return Poisson probabilities per expected number and number\n",
    "def init_prob_lookup():\n",
    "    poss_numbers = range(max(MAX_NUMBER_OF_CARS_LOC_1, MAX_NUMBER_OF_CARS_LOC_2) + 1)\n",
    "    exp_numbers = [EXP_VALUE_RENTALS_LOC_1, EXP_VALUE_RENTALS_LOC_2, EXP_VALUE_RETURNS_LOC_1, EXP_VALUE_RETURNS_LOC_2]\n",
    "        \n",
    "    # create a cartesian product of expected numbers and rental/return numbers\n",
    "    prob_lookup = np.array(np.meshgrid(poss_numbers, exp_numbers, [0.])).T.reshape(-1,3)\n",
    "    prob_lookup[:,2] = get_probsrsa_vectorized(prob_lookup[:,0], prob_lookup[:,1])\n",
    "    return prob_lookup\n",
    "\n",
    "def lookup_prob(number, exp_number):\n",
    "    result = prob_lookup[:, 2][(prob_lookup[:,0].astype(int) == number) & (prob_lookup[:,1].astype(int) == exp_number)]\n",
    "    return np.unique(result)\n",
    "\n",
    "def lookup_prob_vectorized(numbers, exp_number):\n",
    "    probs = [0.] * len(numbers)\n",
    "    for i in range(len(numbers)):\n",
    "        probs[i] = lookup_prob(numbers[i], exp_number)\n",
    "    return probs\n",
    "\n",
    "def softmax_vectorized(x): \n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\" \n",
    "    #e_x = np.exp(x - np.max(x)) # mathematically more stable for larger values of x\n",
    "    e_x = np.exp(x) # but we expect x << 1 for all x, so this is more stable in our case\n",
    "    return e_x / np.unique(e_x).sum(axis=0) \n",
    "\n",
    "# helper function to calculate the rewards from rentals across locations\n",
    "def get_reward(rentals):\n",
    "    return rentals * REWARD_PER_RENTAL\n",
    "\n",
    "def init_temp_df(data):\n",
    "    columns=[\n",
    "        DFCOL_SPRENRET_SPSEUDO,\n",
    "        DFCOL_SPRENRET_RENTALS_A, DFCOL_SPRENRET_RENTALS_B,\n",
    "        DFCOL_SPRENRET_RETURNS_A, DFCOL_SPRENRET_RETURNS_B,\n",
    "        \"p_ren_1\", \"p_ren_2\", \n",
    "        \"p_ret_1\", \"p_ret_2\", \n",
    "        DFCOL_SPRENRET_PROBSRSA,\n",
    "        DFCOL_SPRENRET_REWARD]\n",
    "    \n",
    "    dftemp = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    dftemp = dftemp.astype({\n",
    "        DFCOL_SPRENRET_SPSEUDO: str, \n",
    "        DFCOL_SPRENRET_RENTALS_A: int,\n",
    "        DFCOL_SPRENRET_RENTALS_B: int,\n",
    "        DFCOL_SPRENRET_RETURNS_A: int,\n",
    "        DFCOL_SPRENRET_RETURNS_B: int,\n",
    "        \"p_ren_1\": float, \n",
    "        \"p_ren_2\": float, \n",
    "        \"p_ret_1\": float, \n",
    "        \"p_ret_2\": float, \n",
    "        DFCOL_SPRENRET_PROBSRSA: float,\n",
    "        DFCOL_SPRENRET_REWARD: int\n",
    "    })\n",
    "    \n",
    "    return dftemp\n",
    "\n",
    "# Calculate all valid combinations of pseudo state, returns and rentals\n",
    "prob_lookup = init_prob_lookup()\n",
    "\n",
    "dfSp_Ren_Ret = pd.DataFrame(columns=[\n",
    "    DFCOL_SPRENRET_SPSEUDO,\n",
    "    DFCOL_SPRENRET_RENTALS_A, DFCOL_SPRENRET_RENTALS_B,\n",
    "    DFCOL_SPRENRET_RETURNS_A, DFCOL_SPRENRET_RETURNS_B])\n",
    "\n",
    "ren_a, ren_b = [], []\n",
    "ret_a, ret_b = [], []\n",
    "\n",
    "for ps_a in range(MIN_NUMBER_OF_CARS_LOC_1, MAX_NUMBER_OF_CARS_LOC_1+1):\n",
    "    for ps_b in range(MIN_NUMBER_OF_CARS_LOC_2, MAX_NUMBER_OF_CARS_LOC_2+1):\n",
    "        ren_a = range(ps_a+1)\n",
    "        ren_b = range(ps_b+1)\n",
    "        ret_a = range(MAX_NUMBER_OF_CARS_LOC_1-ps_a+1)\n",
    "        ret_b = range(MAX_NUMBER_OF_CARS_LOC_2-ps_b+1)\n",
    "        \n",
    "        cart_prod = np.array(np.meshgrid(\n",
    "            [get_state_name(str(ps_a), str(ps_b))], \n",
    "            list(ren_a), list(ren_b), list(ret_a), list(ret_b)\n",
    "        )).T.reshape(-1,5)\n",
    "        rest = np.zeros(shape=(cart_prod.shape[0], 6), dtype='int')\n",
    "        cart_prod = np.concatenate((cart_prod, rest), axis=1)\n",
    "        \n",
    "        # re-initialize the dftemp data frame\n",
    "        dftemp = init_temp_df(cart_prod)\n",
    "        #print(dftemp.iloc[:, 1])\n",
    "        \n",
    "        # write the granular probabilities\n",
    "        exp_numbers = [EXP_VALUE_RENTALS_LOC_1, EXP_VALUE_RENTALS_LOC_2, EXP_VALUE_RETURNS_LOC_1, EXP_VALUE_RETURNS_LOC_2]\n",
    "        for i in range(4):\n",
    "            probs = lookup_prob_vectorized(dftemp.iloc[:, 1+i], exp_numbers[i])\n",
    "            dftemp.iloc[:, 5+i] = probs\n",
    "        #print(dftemp)\n",
    "        \n",
    "        # apply a softmax over each probability row\n",
    "        for i in range(4):\n",
    "            probs = softmax_vectorized(dftemp.iloc[:, 5+i])\n",
    "            dftemp.iloc[:, 5+i] = probs\n",
    "        #print(dftemp)\n",
    "            \n",
    "        # compute and write the joint probability\n",
    "        prob_rentals = np.multiply(dftemp.iloc[:, -6:-5], dftemp.iloc[:, -5:-4])\n",
    "        prob_returns = np.multiply(dftemp.iloc[:, -4:-3], dftemp.iloc[:, -3:-2])\n",
    "        dftemp.iloc[:, -2:-1] = np.multiply(prob_rentals.iloc[:,0], prob_returns.iloc[:,0])\n",
    "        \n",
    "        # retire the granular probability columns\n",
    "        dftemp = dftemp.iloc[:, [0,1,2,3,4,9,10]]\n",
    "        # print(dftemp)\n",
    "        \n",
    "        # compute the rewards for rentals\n",
    "        dftemp.iloc[:, -1] = get_reward(dftemp.iloc[:, 1] + dftemp.iloc[:, 2])   \n",
    "        # print(dftemp)\n",
    "        \n",
    "        dfSp_Ren_Ret = dfSp_Ren_Ret.append(pd.DataFrame(dftemp, columns=[\n",
    "            DFCOL_SPRENRET_SPSEUDO,\n",
    "            DFCOL_SPRENRET_RENTALS_A, DFCOL_SPRENRET_RENTALS_B,\n",
    "            DFCOL_SPRENRET_RETURNS_A, DFCOL_SPRENRET_RETURNS_B,\n",
    "            DFCOL_SPRENRET_PROBSRSA,\n",
    "            DFCOL_SPRENRET_REWARD]))\n",
    "        #print(dfSp_Ren_Ret) \n",
    "print(\"dataframe creation done\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe multi-index set, sorted and removed 22:17:43\n",
      "next state computed 22:17:44\n",
      "        s_pseudo_k  rentals_k_a  rentals_k_b  returns_k_a  returns_k_b  \\\n",
      "0            00_00            0            0            0            0   \n",
      "1            00_00            0            0            0            1   \n",
      "2            00_00            0            0            0            2   \n",
      "3            00_00            0            0            0            3   \n",
      "4            00_00            0            0            0            4   \n",
      "5            00_00            0            0            0            5   \n",
      "6            00_00            0            0            0            6   \n",
      "7            00_00            0            0            0            7   \n",
      "8            00_00            0            0            0            8   \n",
      "9            00_00            0            0            0            9   \n",
      "10           00_00            0            0            0           10   \n",
      "11           00_00            0            0            0           11   \n",
      "12           00_00            0            0            0           12   \n",
      "13           00_00            0            0            0           13   \n",
      "14           00_00            0            0            0           14   \n",
      "15           00_00            0            0            0           15   \n",
      "16           00_00            0            0            0           16   \n",
      "17           00_00            0            0            0           17   \n",
      "18           00_00            0            0            0           18   \n",
      "19           00_00            0            0            0           19   \n",
      "20           00_00            0            0            0           20   \n",
      "21           00_00            0            0            1            0   \n",
      "22           00_00            0            0            1            1   \n",
      "23           00_00            0            0            1            2   \n",
      "24           00_00            0            0            1            3   \n",
      "25           00_00            0            0            1            4   \n",
      "26           00_00            0            0            1            5   \n",
      "27           00_00            0            0            1            6   \n",
      "28           00_00            0            0            1            7   \n",
      "29           00_00            0            0            1            8   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "3136411      20_20           19           12            0            0   \n",
      "3136412      20_20           19           13            0            0   \n",
      "3136413      20_20           19           14            0            0   \n",
      "3136414      20_20           19           15            0            0   \n",
      "3136415      20_20           19           16            0            0   \n",
      "3136416      20_20           19           17            0            0   \n",
      "3136417      20_20           19           18            0            0   \n",
      "3136418      20_20           19           19            0            0   \n",
      "3136419      20_20           19           20            0            0   \n",
      "3136420      20_20           20            0            0            0   \n",
      "3136421      20_20           20            1            0            0   \n",
      "3136422      20_20           20            2            0            0   \n",
      "3136423      20_20           20            3            0            0   \n",
      "3136424      20_20           20            4            0            0   \n",
      "3136425      20_20           20            5            0            0   \n",
      "3136426      20_20           20            6            0            0   \n",
      "3136427      20_20           20            7            0            0   \n",
      "3136428      20_20           20            8            0            0   \n",
      "3136429      20_20           20            9            0            0   \n",
      "3136430      20_20           20           10            0            0   \n",
      "3136431      20_20           20           11            0            0   \n",
      "3136432      20_20           20           12            0            0   \n",
      "3136433      20_20           20           13            0            0   \n",
      "3136434      20_20           20           14            0            0   \n",
      "3136435      20_20           20           15            0            0   \n",
      "3136436      20_20           20           16            0            0   \n",
      "3136437      20_20           20           17            0            0   \n",
      "3136438      20_20           20           18            0            0   \n",
      "3136439      20_20           20           19            0            0   \n",
      "3136440      20_20           20           20            0            0   \n",
      "\n",
      "         p_of_srsa  r_k_reward  s_k_plus_1_a  s_k_plus_1_b  \n",
      "0         0.002776         0.0             0             0  \n",
      "1         0.003179         0.0             0             1  \n",
      "2         0.003179         0.0             0             2  \n",
      "3         0.002904         0.0             0             3  \n",
      "4         0.002654         0.0             0             4  \n",
      "5         0.002514         0.0             0             5  \n",
      "6         0.002454         0.0             0             6  \n",
      "7         0.002433         0.0             0             7  \n",
      "8         0.002427         0.0             0             8  \n",
      "9         0.002425         0.0             0             9  \n",
      "10        0.002425         0.0             0            10  \n",
      "11        0.002425         0.0             0            11  \n",
      "12        0.002425         0.0             0            12  \n",
      "13        0.002425         0.0             0            13  \n",
      "14        0.002425         0.0             0            14  \n",
      "15        0.002425         0.0             0            15  \n",
      "16        0.002425         0.0             0            16  \n",
      "17        0.002425         0.0             0            17  \n",
      "18        0.002425         0.0             0            18  \n",
      "19        0.002425         0.0             0            19  \n",
      "20        0.002425         0.0             0            20  \n",
      "21        0.003067         0.0             1             0  \n",
      "22        0.003511         0.0             1             1  \n",
      "23        0.003511         0.0             1             2  \n",
      "24        0.003208         0.0             1             3  \n",
      "25        0.002932         0.0             1             4  \n",
      "26        0.002777         0.0             1             5  \n",
      "27        0.002711         0.0             1             6  \n",
      "28        0.002688         0.0             1             7  \n",
      "29        0.002681         0.0             1             8  \n",
      "...            ...         ...           ...           ...  \n",
      "3136411   0.002302       310.0             1             8  \n",
      "3136412   0.002301       320.0             1             7  \n",
      "3136413   0.002301       330.0             1             6  \n",
      "3136414   0.002301       340.0             1             5  \n",
      "3136415   0.002301       350.0             1             4  \n",
      "3136416   0.002301       360.0             1             3  \n",
      "3136417   0.002301       370.0             1             2  \n",
      "3136418   0.002301       380.0             1             1  \n",
      "3136419   0.002301       390.0             1             0  \n",
      "3136420   0.002343       200.0             0            20  \n",
      "3136421   0.002475       210.0             0            19  \n",
      "3136422   0.002664       220.0             0            18  \n",
      "3136423   0.002797       230.0             0            17  \n",
      "3136424   0.002797       240.0             0            16  \n",
      "3136425   0.002690       250.0             0            15  \n",
      "3136426   0.002553       260.0             0            14  \n",
      "3136427   0.002442       270.0             0            13  \n",
      "3136428   0.002370       280.0             0            12  \n",
      "3136429   0.002331       290.0             0            11  \n",
      "3136430   0.002313       300.0             0            10  \n",
      "3136431   0.002305       310.0             0             9  \n",
      "3136432   0.002302       320.0             0             8  \n",
      "3136433   0.002301       330.0             0             7  \n",
      "3136434   0.002301       340.0             0             6  \n",
      "3136435   0.002301       350.0             0             5  \n",
      "3136436   0.002301       360.0             0             4  \n",
      "3136437   0.002301       370.0             0             3  \n",
      "3136438   0.002301       380.0             0             2  \n",
      "3136439   0.002301       390.0             0             1  \n",
      "3136440   0.002301       400.0             0             0  \n",
      "\n",
      "[3136441 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next state named 22:20:20\n"
     ]
    }
   ],
   "source": [
    "dfSp_Ren_Ret.set_index([DFCOL_SPRENRET_SPSEUDO,\n",
    "            DFCOL_SPRENRET_RENTALS_A, DFCOL_SPRENRET_RENTALS_B,\n",
    "            DFCOL_SPRENRET_RETURNS_A, DFCOL_SPRENRET_RETURNS_B], inplace=True)\n",
    "dfSp_Ren_Ret.sort_index(inplace=True)\n",
    "dfSp_Ren_Ret.reset_index(inplace=True)\n",
    "print(\"dataframe multi-index set, sorted and removed\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# compute the next state, s', from (s_pseudo, rentals_a, rentals_b, returns_a, returns_b)\n",
    "dfSp_Ren_Ret[DFCOL_SPRENRET_SNEXT_A] = dfSp_Ren_Ret[DFCOL_SPRENRET_SPSEUDO].map(dict_states_a).astype(int) - dfSp_Ren_Ret[DFCOL_SPRENRET_RENTALS_A] + dfSp_Ren_Ret[DFCOL_SPRENRET_RETURNS_A]\n",
    "dfSp_Ren_Ret[DFCOL_SPRENRET_SNEXT_B] = dfSp_Ren_Ret[DFCOL_SPRENRET_SPSEUDO].map(dict_states_b).astype(int) - dfSp_Ren_Ret[DFCOL_SPRENRET_RENTALS_B] + dfSp_Ren_Ret[DFCOL_SPRENRET_RETURNS_B]\n",
    "print(\"next state computed\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(dfSp_Ren_Ret)\n",
    "\n",
    "# Compute the next state's name\n",
    "dfSp_Ren_Ret[DFCOL_SPRENRET_SNEXT] = dfSp_Ren_Ret.apply(\n",
    "    lambda d: get_state_name(str(d[DFCOL_SPRENRET_SNEXT_A]), str(d[DFCOL_SPRENRET_SNEXT_B])),\n",
    "    axis=1)\n",
    "print(\"next state named\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        s_pseudo_k  rentals_k_a  rentals_k_b  returns_k_a  returns_k_b  \\\n",
      "0            00_00            0            0            0            0   \n",
      "1            00_00            0            0            0            1   \n",
      "2            00_00            0            0            0            2   \n",
      "3            00_00            0            0            0            3   \n",
      "4            00_00            0            0            0            4   \n",
      "5            00_00            0            0            0            5   \n",
      "6            00_00            0            0            0            6   \n",
      "7            00_00            0            0            0            7   \n",
      "8            00_00            0            0            0            8   \n",
      "9            00_00            0            0            0            9   \n",
      "10           00_00            0            0            0           10   \n",
      "11           00_00            0            0            0           11   \n",
      "12           00_00            0            0            0           12   \n",
      "13           00_00            0            0            0           13   \n",
      "14           00_00            0            0            0           14   \n",
      "15           00_00            0            0            0           15   \n",
      "16           00_00            0            0            0           16   \n",
      "17           00_00            0            0            0           17   \n",
      "18           00_00            0            0            0           18   \n",
      "19           00_00            0            0            0           19   \n",
      "20           00_00            0            0            0           20   \n",
      "21           00_00            0            0            1            0   \n",
      "22           00_00            0            0            1            1   \n",
      "23           00_00            0            0            1            2   \n",
      "24           00_00            0            0            1            3   \n",
      "25           00_00            0            0            1            4   \n",
      "26           00_00            0            0            1            5   \n",
      "27           00_00            0            0            1            6   \n",
      "28           00_00            0            0            1            7   \n",
      "29           00_00            0            0            1            8   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "3136411      20_20           19           12            0            0   \n",
      "3136412      20_20           19           13            0            0   \n",
      "3136413      20_20           19           14            0            0   \n",
      "3136414      20_20           19           15            0            0   \n",
      "3136415      20_20           19           16            0            0   \n",
      "3136416      20_20           19           17            0            0   \n",
      "3136417      20_20           19           18            0            0   \n",
      "3136418      20_20           19           19            0            0   \n",
      "3136419      20_20           19           20            0            0   \n",
      "3136420      20_20           20            0            0            0   \n",
      "3136421      20_20           20            1            0            0   \n",
      "3136422      20_20           20            2            0            0   \n",
      "3136423      20_20           20            3            0            0   \n",
      "3136424      20_20           20            4            0            0   \n",
      "3136425      20_20           20            5            0            0   \n",
      "3136426      20_20           20            6            0            0   \n",
      "3136427      20_20           20            7            0            0   \n",
      "3136428      20_20           20            8            0            0   \n",
      "3136429      20_20           20            9            0            0   \n",
      "3136430      20_20           20           10            0            0   \n",
      "3136431      20_20           20           11            0            0   \n",
      "3136432      20_20           20           12            0            0   \n",
      "3136433      20_20           20           13            0            0   \n",
      "3136434      20_20           20           14            0            0   \n",
      "3136435      20_20           20           15            0            0   \n",
      "3136436      20_20           20           16            0            0   \n",
      "3136437      20_20           20           17            0            0   \n",
      "3136438      20_20           20           18            0            0   \n",
      "3136439      20_20           20           19            0            0   \n",
      "3136440      20_20           20           20            0            0   \n",
      "\n",
      "         p_of_srsa  r_k_reward  s_k_plus_1_a  s_k_plus_1_b s_k_plus_1  \n",
      "0         0.002776         0.0             0             0      00_00  \n",
      "1         0.003179         0.0             0             1      00_01  \n",
      "2         0.003179         0.0             0             2      00_02  \n",
      "3         0.002904         0.0             0             3      00_03  \n",
      "4         0.002654         0.0             0             4      00_04  \n",
      "5         0.002514         0.0             0             5      00_05  \n",
      "6         0.002454         0.0             0             6      00_06  \n",
      "7         0.002433         0.0             0             7      00_07  \n",
      "8         0.002427         0.0             0             8      00_08  \n",
      "9         0.002425         0.0             0             9      00_09  \n",
      "10        0.002425         0.0             0            10      00_10  \n",
      "11        0.002425         0.0             0            11      00_11  \n",
      "12        0.002425         0.0             0            12      00_12  \n",
      "13        0.002425         0.0             0            13      00_13  \n",
      "14        0.002425         0.0             0            14      00_14  \n",
      "15        0.002425         0.0             0            15      00_15  \n",
      "16        0.002425         0.0             0            16      00_16  \n",
      "17        0.002425         0.0             0            17      00_17  \n",
      "18        0.002425         0.0             0            18      00_18  \n",
      "19        0.002425         0.0             0            19      00_19  \n",
      "20        0.002425         0.0             0            20      00_20  \n",
      "21        0.003067         0.0             1             0      01_00  \n",
      "22        0.003511         0.0             1             1      01_01  \n",
      "23        0.003511         0.0             1             2      01_02  \n",
      "24        0.003208         0.0             1             3      01_03  \n",
      "25        0.002932         0.0             1             4      01_04  \n",
      "26        0.002777         0.0             1             5      01_05  \n",
      "27        0.002711         0.0             1             6      01_06  \n",
      "28        0.002688         0.0             1             7      01_07  \n",
      "29        0.002681         0.0             1             8      01_08  \n",
      "...            ...         ...           ...           ...        ...  \n",
      "3136411   0.002302       310.0             1             8      01_08  \n",
      "3136412   0.002301       320.0             1             7      01_07  \n",
      "3136413   0.002301       330.0             1             6      01_06  \n",
      "3136414   0.002301       340.0             1             5      01_05  \n",
      "3136415   0.002301       350.0             1             4      01_04  \n",
      "3136416   0.002301       360.0             1             3      01_03  \n",
      "3136417   0.002301       370.0             1             2      01_02  \n",
      "3136418   0.002301       380.0             1             1      01_01  \n",
      "3136419   0.002301       390.0             1             0      01_00  \n",
      "3136420   0.002343       200.0             0            20      00_20  \n",
      "3136421   0.002475       210.0             0            19      00_19  \n",
      "3136422   0.002664       220.0             0            18      00_18  \n",
      "3136423   0.002797       230.0             0            17      00_17  \n",
      "3136424   0.002797       240.0             0            16      00_16  \n",
      "3136425   0.002690       250.0             0            15      00_15  \n",
      "3136426   0.002553       260.0             0            14      00_14  \n",
      "3136427   0.002442       270.0             0            13      00_13  \n",
      "3136428   0.002370       280.0             0            12      00_12  \n",
      "3136429   0.002331       290.0             0            11      00_11  \n",
      "3136430   0.002313       300.0             0            10      00_10  \n",
      "3136431   0.002305       310.0             0             9      00_09  \n",
      "3136432   0.002302       320.0             0             8      00_08  \n",
      "3136433   0.002301       330.0             0             7      00_07  \n",
      "3136434   0.002301       340.0             0             6      00_06  \n",
      "3136435   0.002301       350.0             0             5      00_05  \n",
      "3136436   0.002301       360.0             0             4      00_04  \n",
      "3136437   0.002301       370.0             0             3      00_03  \n",
      "3136438   0.002301       380.0             0             2      00_02  \n",
      "3136439   0.002301       390.0             0             1      00_01  \n",
      "3136440   0.002301       400.0             0             0      00_00  \n",
      "\n",
      "[3136441 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfSp_Ren_Ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH_SPRENRET_CSV):\n",
    "    os.makedirs(PATH_SPRENRET_CSV)\n",
    "    \n",
    "file_name = \"dfSp_Ren_Ret.csv\"\n",
    "abs_file_name = os.path.join(PATH_SPRENRET_CSV, file_name)\n",
    "dfSp_Ren_Ret.to_csv(path_or_buf=abs_file_name, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   s_pseudo_k  rentals_k_a  rentals_k_b  returns_k_a  returns_k_b  p_of_srsa  \\\n",
      "0       00_00            0            0            0            0   0.002776   \n",
      "1       00_00            0            0            0            1   0.003179   \n",
      "2       00_00            0            0            0            2   0.003179   \n",
      "3       00_00            0            0            0            3   0.002904   \n",
      "4       00_00            0            0            0            4   0.002654   \n",
      "5       00_00            0            0            0            5   0.002514   \n",
      "6       00_00            0            0            0            6   0.002454   \n",
      "7       00_00            0            0            0            7   0.002433   \n",
      "8       00_00            0            0            0            8   0.002427   \n",
      "9       00_00            0            0            0            9   0.002425   \n",
      "10      00_00            0            0            0           10   0.002425   \n",
      "11      00_00            0            0            0           11   0.002425   \n",
      "12      00_00            0            0            0           12   0.002425   \n",
      "13      00_00            0            0            0           13   0.002425   \n",
      "14      00_00            0            0            0           14   0.002425   \n",
      "15      00_00            0            0            0           15   0.002425   \n",
      "16      00_00            0            0            0           16   0.002425   \n",
      "17      00_00            0            0            0           17   0.002425   \n",
      "18      00_00            0            0            0           18   0.002425   \n",
      "19      00_00            0            0            0           19   0.002425   \n",
      "\n",
      "    r_k_reward  s_k_plus_1_a  s_k_plus_1_b s_k_plus_1  \n",
      "0          0.0             0             0      00_00  \n",
      "1          0.0             0             1      00_01  \n",
      "2          0.0             0             2      00_02  \n",
      "3          0.0             0             3      00_03  \n",
      "4          0.0             0             4      00_04  \n",
      "5          0.0             0             5      00_05  \n",
      "6          0.0             0             6      00_06  \n",
      "7          0.0             0             7      00_07  \n",
      "8          0.0             0             8      00_08  \n",
      "9          0.0             0             9      00_09  \n",
      "10         0.0             0            10      00_10  \n",
      "11         0.0             0            11      00_11  \n",
      "12         0.0             0            12      00_12  \n",
      "13         0.0             0            13      00_13  \n",
      "14         0.0             0            14      00_14  \n",
      "15         0.0             0            15      00_15  \n",
      "16         0.0             0            16      00_16  \n",
      "17         0.0             0            17      00_17  \n",
      "18         0.0             0            18      00_18  \n",
      "19         0.0             0            19      00_19  \n"
     ]
    }
   ],
   "source": [
    "dfSp_Ren_Ret = pd.read_csv(filepath_or_buffer=abs_file_name, sep='\\t', encoding='utf-8', index_col=0)\n",
    "print(dfSp_Ren_Ret.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_values(mode=\"PolicyEval\"):\n",
    "    gamma = 0.9\n",
    "    theta = 0.01\n",
    "    delta = 0.\n",
    "    v = 0.\n",
    "    new_v = 0.\n",
    "    policy_stable = True\n",
    "    maximizing_action = None\n",
    "    maximum_value = -100000.\n",
    "    \n",
    "    df = None\n",
    "    col_state = None\n",
    "    \n",
    "    if mode == \"PolicyEval\":\n",
    "        df = dfV\n",
    "        col_state = DFCOL_V_STATE\n",
    "    elif mode == \"PolicyImprove\":\n",
    "        df = dfPi\n",
    "        col_state = DFCOL_PI_STATE\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # the current state, interpreted as original state\n",
    "        orig_state = row[col_state]\n",
    "        print(\"orig_state = \" + orig_state)\n",
    "        \n",
    "        if mode == \"PolicyEval\":\n",
    "            # the current value for the original state\n",
    "            v = row[DFCOL_V_VALUE]\n",
    "            \n",
    "            # init the new value at 0. to keep adding partial values to it later\n",
    "            new_v = 0.\n",
    "        elif mode == \"PolicyImprove\":\n",
    "            maximum_value = -100000.\n",
    "            maximizing_action = None\n",
    "        \n",
    "        # the action currently produced by the greedy policy for the original state\n",
    "        action = dfPi.loc[dfPi[DFCOL_PI_STATE] == orig_state, DFCOL_PI_ACTION].values[0]\n",
    "        print(\"action = \" + str(action))\n",
    "\n",
    "        # legitimate actions for the state vary dependent on mode\n",
    "        legit_actions = []\n",
    "        if mode == \"PolicyEval\":\n",
    "            # we'll only use the current action from the current greedy policy\n",
    "            legit_actions = [action]\n",
    "        elif mode == \"PolicyImprove\":\n",
    "            # we'll iterate through all legitimate actions, ignoring current greedy policy\n",
    "            legit_actions = dfSASP.loc[dfSASP[DFCOL_SASP_SORIG] == orig_state, [DFCOL_SASP_ACTION]].tolist()\n",
    "        #print(\"legit_actions = \" + str(legit_actions))\n",
    "            \n",
    "        for action in legit_actions:\n",
    "            # the pseudo-state the original state and current action lead to\n",
    "            #print(orig_state + \" : \" + str(action))\n",
    "            pseudo_state = dfSASP.loc[\n",
    "                (dfSASP[DFCOL_SASP_SORIG] == orig_state) & (dfSASP[DFCOL_SASP_ACTION] == action), \n",
    "                DFCOL_SASP_SPSEUDO].values[0]\n",
    "            print(\"pseudo_state = \" + pseudo_state)\n",
    "\n",
    "            # the penalty the current action incurs\n",
    "            action_penalty = dfSASP.loc[dfSASP[DFCOL_SASP_SORIG] == orig_state, \n",
    "                                 [DFCOL_SASP_ACTION, \n",
    "                                  DFCOL_SASP_FEES]].loc[dfSASP[DFCOL_SASP_ACTION] == action, \n",
    "                                                        DFCOL_SASP_FEES].values[0]\n",
    "            print(\"action_penalty = \" + str(action_penalty))\n",
    "            \n",
    "            # dataframe dfProbs holds the following columns from dfSp_Ren_Ret that correspond to the pseudo-state:\n",
    "            # (1) all valid rental&return count combinations across locations\n",
    "            # DFCOL_SPRENRET_RENTALS_A, DFCOL_SPRENRET_RENTALS_B, DFCOL_SPRENRET_RETURNS_A, DFCOL_SPRENRET_RETURNS_B, \n",
    "            # (2) their corresponding next state\n",
    "            # DFCOL_SPRENRET_SNEXT\n",
    "            # (3) their respective Poisson probabilities\n",
    "            # DFCOL_SPRENRET_PROBSRSA, \n",
    "            # (4) their respective reward\n",
    "            # DFCOL_SPRENRET_REWARD\n",
    "            dfProbs = dfSp_Ren_Ret.loc[dfSp_Ren_Ret[DFCOL_SPRENRET_SPSEUDO] == pseudo_state, \n",
    "                                       [DFCOL_SPRENRET_RENTALS_A, \n",
    "                                        DFCOL_SPRENRET_RENTALS_B, \n",
    "                                        DFCOL_SPRENRET_RETURNS_A, \n",
    "                                        DFCOL_SPRENRET_RETURNS_B, \n",
    "                                        DFCOL_SPRENRET_SNEXT,\n",
    "                                        DFCOL_SPRENRET_PROBSRSA, \n",
    "                                        DFCOL_SPRENRET_REWARD]]\n",
    "            #print(\"initialized dataframe dfProbs for pseudo state \" + pseudo_state, datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            #print(dfProbs)\n",
    "\n",
    "            if mode == \"PolicyEval\":\n",
    "                # loop through dfProbs and add to the state's value the probability-weighted average of \n",
    "                # (reward plus discounted next-state value) over next states and their rewards\n",
    "                for index_probs, row_probs in dfProbs.iterrows():\n",
    "                    # the next state\n",
    "                    next_state = row_probs[DFCOL_SPRENRET_SNEXT]\n",
    "\n",
    "                    # the next state's value\n",
    "                    next_state_v = dfV.loc[dfV[DFCOL_V_STATE] == next_state, DFCOL_V_VALUE].values[0]\n",
    "\n",
    "                    # the partial value the next state produces\n",
    "                    new_v += row_probs[DFCOL_SPRENRET_PROBSRSA]*(float(row_probs[DFCOL_SPRENRET_REWARD] - action_penalty) + gamma*next_state_v)\n",
    "\n",
    "                # update dfV with the new value for this state\n",
    "                dfV.loc[index, DFCOL_V_VALUE] = new_v\n",
    "                print(\"new value found for state \" + orig_state + \": \" + str(dfV.loc[index, DFCOL_V_VALUE]))\n",
    "                \n",
    "            elif mode == \"PolicyImprove\":\n",
    "                # loop through dfProbs and look for the action that would maximize the state's value\n",
    "                new_v = 0.\n",
    "                for index_probs, row_probs in dfProbs.iterrows():\n",
    "                    # the next state\n",
    "                    next_state = row_probs[DFCOL_SPRENRET_SNEXT]\n",
    "\n",
    "                    # the next state's value\n",
    "                    next_state_v = dfV.loc[dfV[DFCOL_V_STATE] == next_state, DFCOL_V_VALUE].values[0]\n",
    "\n",
    "                    # the partial value the next state produces\n",
    "                    new_v += row_probs[DFCOL_SPRENRET_PROBSRSA]*(float(row_probs[DFCOL_SPRENRET_REWARD] - action_penalty) + gamma*next_state_v)\n",
    "\n",
    "                # if the computed state value is larger than seen so far, then the current action is a maximizer\n",
    "                if maximum_value < new_v:\n",
    "                    maximum_value = max(maximum_value, new_v)\n",
    "                    maximizing_action = action\n",
    "\n",
    "        if mode == \"PolicyEval\":\n",
    "            # keep record of the greatest yet delta between an old and a new state value within this iteration \n",
    "            delta = max(delta, abs(v - new_v))\n",
    "            #print(\"delta = \" + str(delta))\n",
    "        elif mode == \"PolicyImprove\":\n",
    "            # record any new maximizing action for the state\n",
    "            dfPi.loc[index, DFCOL_PI_ACTION] = maximizing_action\n",
    "            new_v = maximum_value\n",
    "            \n",
    "            if action != maximizing_action and v < new_v: \n",
    "                policy_stable = False\n",
    "    \n",
    "    if mode == \"PolicyEval\":\n",
    "        # stop and declare a good-enough value function if the greatest delta of last iteration is sufficiently small\n",
    "        if(delta < theta): \n",
    "            # good enough\n",
    "            print(\"values deemed good enough\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            print(dfV)\n",
    "            return True \n",
    "        else:\n",
    "            # not yet good enough\n",
    "            print(\"values deemed not good enough, going for another value loop\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            print(dfV)\n",
    "            return False\n",
    "    elif mode == \"PolicyImprove\":\n",
    "        if policy_stable == True:\n",
    "            # the policy is considered stable enough, so last computed values remains valid\n",
    "            print(\"policy considered stable enough\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            print(dfPi)\n",
    "            pass\n",
    "        else:\n",
    "            # a better policy was found, so policy evaluation must update the last computed values\n",
    "            print(\"a better policy was found, going for another value loop\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "            print(dfPi)\n",
    "            policy_evaluation()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized dataframe dfPi 23:15:28\n",
      "(re)set index for dfPi 23:15:28\n",
      "initialized dataframe dfV 23:15:28\n",
      "(re)set index for dfV 23:15:28\n"
     ]
    }
   ],
   "source": [
    "# (1) Initialize Policy Iteration\n",
    "\n",
    "# dataframe dfPi - init with default action = 5 (= 0 transfers)\n",
    "mindex = pd.MultiIndex.from_product(\n",
    "                [all_states[:,-1]],\n",
    "                names=[DFCOL_PI_STATE]\n",
    "            )\n",
    "dfPi = pd.DataFrame(\n",
    "            {\n",
    "                DFCOL_PI_ACTION: [5]*num_states\n",
    "            },\n",
    "            index = mindex)\n",
    "print(\"initialized dataframe dfPi\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "dfPi.reset_index(inplace=True)\n",
    "#dfPi.set_index(DFCOL_PI_STATE)\n",
    "print(\"(re)set index for dfPi\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# dataframe dfV - init with default value = 0\n",
    "mindex = pd.MultiIndex.from_product(\n",
    "                [all_states[:,-1]],\n",
    "                names=[DFCOL_V_STATE]\n",
    "            )\n",
    "dfV = pd.DataFrame(\n",
    "            {\n",
    "                DFCOL_V_VALUE: [0.]*num_states\n",
    "            },\n",
    "            index = mindex)\n",
    "print(\"initialized dataframe dfV\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "dfV.reset_index(inplace=True)\n",
    "#dfPi.set_index(DFCOL_V_STATE)\n",
    "print(\"(re)set index for dfV\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Policy Evaluation\n",
    "\n",
    "def policy_evaluation():\n",
    "    good_enough = False\n",
    "    \n",
    "    while True:\n",
    "        good_enough = iter_values(mode=\"PolicyEval\") \n",
    "        if good_enough: break\n",
    "            \n",
    "    policy_improvement()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Policy Improvement\n",
    "\n",
    "def policy_improvement():\n",
    "    iter_values(mode=\"PolicyImprove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_state = 00_00\n",
      "action = 5\n",
      "pseudo_state = 00_00\n",
      "action_penalty = 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'s_pseudo_k'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 's_pseudo_k'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-406-edd3bf88bcd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpolicy_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-404-ec65aed009cc>\u001b[0m in \u001b[0;36mpolicy_evaluation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mgood_enough\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"PolicyEval\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgood_enough\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-402-d3c38e21a953>\u001b[0m in \u001b[0;36miter_values\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;31m# (4) their respective reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;31m# DFCOL_SPRENRET_REWARD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             dfProbs = dfSp_Ren_Ret.loc[dfSp_Ren_Ret[DFCOL_SPRENRET_SPSEUDO] == pseudo_state, \n\u001b[0m\u001b[0;32m     75\u001b[0m                                        [DFCOL_SPRENRET_RENTALS_A, \n\u001b[0;32m     76\u001b[0m                                         \u001b[0mDFCOL_SPRENRET_RENTALS_B\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 's_pseudo_k'"
     ]
    }
   ],
   "source": [
    "policy_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducing the original Jack's Car Rental Problem (Example 4.2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting the solution for the additional requirements (Ex. 4.7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_FIRST_CHARGEABLE_TRANSFER = 1\n",
    "INDEX_LAST_CHARGEABLE_TRANSFER = 4\n",
    "UNIT_COST_OF_TRANSFER = 2\n",
    "INDEX_FIRST_CHARGEABLE_PARKING = 10\n",
    "FLAT_COST_OFPARKING = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.8\n",
    "\n",
    "## Question:\n",
    "Why does the optimal policy for the gambler's problem have such a curious form? In particular, for capital of 50 it bets it all on one flip, but for capital of 51 it does not. Why is this a good policy?\n",
    "\n",
    "## Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.9 (programming)\n",
    "\n",
    "## Question:\n",
    "Implement value iteration for the gambler's problem and solve it for for $p_h = 0.25$ and $p_h = 0.55$. In programming, you may find it convenient to introduce two dummy states corresponding to termination with capital 0 or 100, giving them values of 0 and 1 respectively. Show your results graphically, as in Figure 4.3. Are your results stable as $\\theta \\rightarrow 0$?  \n",
    "\n",
    "## Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.10\n",
    "\n",
    "## Question:\n",
    "What is the analog of the value iteration update (4.10) for action values, $q_{k+1}(s,a)$?\n",
    "\n",
    "## Answer:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
